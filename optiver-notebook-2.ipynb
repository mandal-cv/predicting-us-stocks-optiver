{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set Up","metadata":{}},{"cell_type":"code","source":"# !pip install cuml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:50:40.201809Z","iopub.execute_input":"2024-12-14T06:50:40.202334Z","iopub.status.idle":"2024-12-14T06:50:40.221575Z","shell.execute_reply.started":"2024-12-14T06:50:40.202290Z","shell.execute_reply":"2024-12-14T06:50:40.220932Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nimport math\nimport seaborn as sb","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:40.232325Z","iopub.execute_input":"2024-12-14T06:50:40.232585Z","iopub.status.idle":"2024-12-14T06:50:43.204966Z","shell.execute_reply.started":"2024-12-14T06:50:40.232558Z","shell.execute_reply":"2024-12-14T06:50:43.204133Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Suppress Warnings for clean notebook\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:43.206555Z","iopub.execute_input":"2024-12-14T06:50:43.206937Z","iopub.status.idle":"2024-12-14T06:50:43.212664Z","shell.execute_reply.started":"2024-12-14T06:50:43.206908Z","shell.execute_reply":"2024-12-14T06:50:43.210800Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Data Loading and Exploration\n\n## Loading the Train Dataset\n\nLoading all the datasets in pandas dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:43.213881Z","iopub.execute_input":"2024-12-14T06:50:43.214301Z","iopub.status.idle":"2024-12-14T06:50:59.642469Z","shell.execute_reply.started":"2024-12-14T06:50:43.214225Z","shell.execute_reply":"2024-12-14T06:50:59.641423Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Exploring the data\n### View the First Few Rows of the Dataset:\nUse the head() method to display the first few rows of the training dataset. This will give you an initial glimpse of the data's structure.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:59.645085Z","iopub.execute_input":"2024-12-14T06:50:59.645597Z","iopub.status.idle":"2024-12-14T06:50:59.670635Z","shell.execute_reply.started":"2024-12-14T06:50:59.645550Z","shell.execute_reply":"2024-12-14T06:50:59.669706Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n0         0        0                  0      3180602.69   \n1         1        0                  0       166603.91   \n2         2        0                  0       302879.87   \n3         3        0                  0     11917682.27   \n4         4        0                  0       447549.96   \n\n   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n0                        1         0.999812   13380276.64        NaN   \n1                       -1         0.999896    1642214.25        NaN   \n2                       -1         0.999561    1819368.03        NaN   \n3                       -1         1.000171   18389745.62        NaN   \n4                       -1         0.999532   17860614.95        NaN   \n\n   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n\n   time_id row_id  \n0        0  0_0_0  \n1        0  0_0_1  \n2        0  0_0_2  \n3        0  0_0_3  \n4        0  0_0_4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>date_id</th>\n      <th>seconds_in_bucket</th>\n      <th>imbalance_size</th>\n      <th>imbalance_buy_sell_flag</th>\n      <th>reference_price</th>\n      <th>matched_size</th>\n      <th>far_price</th>\n      <th>near_price</th>\n      <th>bid_price</th>\n      <th>bid_size</th>\n      <th>ask_price</th>\n      <th>ask_size</th>\n      <th>wap</th>\n      <th>target</th>\n      <th>time_id</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3180602.69</td>\n      <td>1</td>\n      <td>0.999812</td>\n      <td>13380276.64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999812</td>\n      <td>60651.50</td>\n      <td>1.000026</td>\n      <td>8493.03</td>\n      <td>1.0</td>\n      <td>-3.029704</td>\n      <td>0</td>\n      <td>0_0_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>166603.91</td>\n      <td>-1</td>\n      <td>0.999896</td>\n      <td>1642214.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999896</td>\n      <td>3233.04</td>\n      <td>1.000660</td>\n      <td>20605.09</td>\n      <td>1.0</td>\n      <td>-5.519986</td>\n      <td>0</td>\n      <td>0_0_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>302879.87</td>\n      <td>-1</td>\n      <td>0.999561</td>\n      <td>1819368.03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999403</td>\n      <td>37956.00</td>\n      <td>1.000298</td>\n      <td>18995.00</td>\n      <td>1.0</td>\n      <td>-8.389950</td>\n      <td>0</td>\n      <td>0_0_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11917682.27</td>\n      <td>-1</td>\n      <td>1.000171</td>\n      <td>18389745.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999999</td>\n      <td>2324.90</td>\n      <td>1.000214</td>\n      <td>479032.40</td>\n      <td>1.0</td>\n      <td>-4.010200</td>\n      <td>0</td>\n      <td>0_0_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>447549.96</td>\n      <td>-1</td>\n      <td>0.999532</td>\n      <td>17860614.95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999394</td>\n      <td>16485.54</td>\n      <td>1.000016</td>\n      <td>434.10</td>\n      <td>1.0</td>\n      <td>-7.349849</td>\n      <td>0</td>\n      <td>0_0_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### Check Basic Dataset Information:\nUse the info() method to get an overview of the dataset's columns, data types, and the number of non-null values. This will help you identify missing data.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:59.671631Z","iopub.execute_input":"2024-12-14T06:50:59.671923Z","iopub.status.idle":"2024-12-14T06:50:59.694267Z","shell.execute_reply.started":"2024-12-14T06:50:59.671886Z","shell.execute_reply":"2024-12-14T06:50:59.693259Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5237980 entries, 0 to 5237979\nData columns (total 17 columns):\n #   Column                   Dtype  \n---  ------                   -----  \n 0   stock_id                 int64  \n 1   date_id                  int64  \n 2   seconds_in_bucket        int64  \n 3   imbalance_size           float64\n 4   imbalance_buy_sell_flag  int64  \n 5   reference_price          float64\n 6   matched_size             float64\n 7   far_price                float64\n 8   near_price               float64\n 9   bid_price                float64\n 10  bid_size                 float64\n 11  ask_price                float64\n 12  ask_size                 float64\n 13  wap                      float64\n 14  target                   float64\n 15  time_id                  int64  \n 16  row_id                   object \ndtypes: float64(11), int64(5), object(1)\nmemory usage: 679.4+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Summary Statistics:\nUse the describe() method to generate summary statistics for numerical columns. This includes statistics like mean, standard deviation, minimum, maximum, and quartiles.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:50:59.695393Z","iopub.execute_input":"2024-12-14T06:50:59.695708Z","iopub.status.idle":"2024-12-14T06:51:03.706125Z","shell.execute_reply.started":"2024-12-14T06:50:59.695678Z","shell.execute_reply":"2024-12-14T06:51:03.705034Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           stock_id       date_id  seconds_in_bucket  imbalance_size  \\\ncount  5.237980e+06  5.237980e+06       5.237980e+06    5.237760e+06   \nmean   9.928856e+01  2.415100e+02       2.700000e+02    5.715293e+06   \nstd    5.787176e+01  1.385319e+02       1.587451e+02    2.051591e+07   \nmin    0.000000e+00  0.000000e+00       0.000000e+00    0.000000e+00   \n25%    4.900000e+01  1.220000e+02       1.300000e+02    8.453415e+04   \n50%    9.900000e+01  2.420000e+02       2.700000e+02    1.113604e+06   \n75%    1.490000e+02  3.610000e+02       4.100000e+02    4.190951e+06   \nmax    1.990000e+02  4.800000e+02       5.400000e+02    2.982028e+09   \n\n       imbalance_buy_sell_flag  reference_price  matched_size     far_price  \\\ncount             5.237980e+06     5.237760e+06  5.237760e+06  2.343638e+06   \nmean             -1.189619e-02     9.999955e-01  4.510025e+07  1.001713e+00   \nstd               8.853374e-01     2.532497e-03  1.398413e+08  7.214705e-01   \nmin              -1.000000e+00     9.352850e-01  4.316610e+03  7.700000e-05   \n25%              -1.000000e+00     9.987630e-01  5.279575e+06  9.963320e-01   \n50%               0.000000e+00     9.999670e-01  1.288264e+07  9.998830e-01   \n75%               1.000000e+00     1.001174e+00  3.270013e+07  1.003318e+00   \nmax               1.000000e+00     1.077488e+00  7.713682e+09  4.379531e+02   \n\n         near_price     bid_price      bid_size     ask_price      ask_size  \\\ncount  2.380800e+06  5.237760e+06  5.237980e+06  5.237760e+06  5.237980e+06   \nmean   9.996601e-01  9.997263e-01  5.181359e+04  1.000264e+00  5.357568e+04   \nstd    1.216920e-02  2.499345e-03  1.114214e+05  2.510042e-03  1.293554e+05   \nmin    7.869880e-01  9.349150e-01  0.000000e+00  9.398270e-01  0.000000e+00   \n25%    9.971000e-01  9.985290e-01  7.374720e+03  9.990290e-01  7.823700e+03   \n50%    9.998890e-01  9.997280e-01  2.196900e+04  1.000207e+00  2.301792e+04   \n75%    1.002590e+00  1.000905e+00  5.583168e+04  1.001414e+00  5.787841e+04   \nmax    1.309732e+00  1.077488e+00  3.028784e+07  1.077836e+00  5.440500e+07   \n\n                wap        target       time_id  \ncount  5.237760e+06  5.237892e+06  5.237980e+06  \nmean   9.999920e-01 -4.756125e-02  1.331005e+04  \nstd    2.497509e-03  9.452860e+00  7.619271e+03  \nmin    9.380080e-01 -3.852898e+02  0.000000e+00  \n25%    9.987810e-01 -4.559755e+00  6.729000e+03  \n50%    9.999970e-01 -6.020069e-02  1.334500e+04  \n75%    1.001149e+00  4.409552e+00  1.990700e+04  \nmax    1.077675e+00  4.460704e+02  2.645400e+04  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>date_id</th>\n      <th>seconds_in_bucket</th>\n      <th>imbalance_size</th>\n      <th>imbalance_buy_sell_flag</th>\n      <th>reference_price</th>\n      <th>matched_size</th>\n      <th>far_price</th>\n      <th>near_price</th>\n      <th>bid_price</th>\n      <th>bid_size</th>\n      <th>ask_price</th>\n      <th>ask_size</th>\n      <th>wap</th>\n      <th>target</th>\n      <th>time_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.237980e+06</td>\n      <td>5.237980e+06</td>\n      <td>5.237980e+06</td>\n      <td>5.237760e+06</td>\n      <td>5.237980e+06</td>\n      <td>5.237760e+06</td>\n      <td>5.237760e+06</td>\n      <td>2.343638e+06</td>\n      <td>2.380800e+06</td>\n      <td>5.237760e+06</td>\n      <td>5.237980e+06</td>\n      <td>5.237760e+06</td>\n      <td>5.237980e+06</td>\n      <td>5.237760e+06</td>\n      <td>5.237892e+06</td>\n      <td>5.237980e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.928856e+01</td>\n      <td>2.415100e+02</td>\n      <td>2.700000e+02</td>\n      <td>5.715293e+06</td>\n      <td>-1.189619e-02</td>\n      <td>9.999955e-01</td>\n      <td>4.510025e+07</td>\n      <td>1.001713e+00</td>\n      <td>9.996601e-01</td>\n      <td>9.997263e-01</td>\n      <td>5.181359e+04</td>\n      <td>1.000264e+00</td>\n      <td>5.357568e+04</td>\n      <td>9.999920e-01</td>\n      <td>-4.756125e-02</td>\n      <td>1.331005e+04</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.787176e+01</td>\n      <td>1.385319e+02</td>\n      <td>1.587451e+02</td>\n      <td>2.051591e+07</td>\n      <td>8.853374e-01</td>\n      <td>2.532497e-03</td>\n      <td>1.398413e+08</td>\n      <td>7.214705e-01</td>\n      <td>1.216920e-02</td>\n      <td>2.499345e-03</td>\n      <td>1.114214e+05</td>\n      <td>2.510042e-03</td>\n      <td>1.293554e+05</td>\n      <td>2.497509e-03</td>\n      <td>9.452860e+00</td>\n      <td>7.619271e+03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>-1.000000e+00</td>\n      <td>9.352850e-01</td>\n      <td>4.316610e+03</td>\n      <td>7.700000e-05</td>\n      <td>7.869880e-01</td>\n      <td>9.349150e-01</td>\n      <td>0.000000e+00</td>\n      <td>9.398270e-01</td>\n      <td>0.000000e+00</td>\n      <td>9.380080e-01</td>\n      <td>-3.852898e+02</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.900000e+01</td>\n      <td>1.220000e+02</td>\n      <td>1.300000e+02</td>\n      <td>8.453415e+04</td>\n      <td>-1.000000e+00</td>\n      <td>9.987630e-01</td>\n      <td>5.279575e+06</td>\n      <td>9.963320e-01</td>\n      <td>9.971000e-01</td>\n      <td>9.985290e-01</td>\n      <td>7.374720e+03</td>\n      <td>9.990290e-01</td>\n      <td>7.823700e+03</td>\n      <td>9.987810e-01</td>\n      <td>-4.559755e+00</td>\n      <td>6.729000e+03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.900000e+01</td>\n      <td>2.420000e+02</td>\n      <td>2.700000e+02</td>\n      <td>1.113604e+06</td>\n      <td>0.000000e+00</td>\n      <td>9.999670e-01</td>\n      <td>1.288264e+07</td>\n      <td>9.998830e-01</td>\n      <td>9.998890e-01</td>\n      <td>9.997280e-01</td>\n      <td>2.196900e+04</td>\n      <td>1.000207e+00</td>\n      <td>2.301792e+04</td>\n      <td>9.999970e-01</td>\n      <td>-6.020069e-02</td>\n      <td>1.334500e+04</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.490000e+02</td>\n      <td>3.610000e+02</td>\n      <td>4.100000e+02</td>\n      <td>4.190951e+06</td>\n      <td>1.000000e+00</td>\n      <td>1.001174e+00</td>\n      <td>3.270013e+07</td>\n      <td>1.003318e+00</td>\n      <td>1.002590e+00</td>\n      <td>1.000905e+00</td>\n      <td>5.583168e+04</td>\n      <td>1.001414e+00</td>\n      <td>5.787841e+04</td>\n      <td>1.001149e+00</td>\n      <td>4.409552e+00</td>\n      <td>1.990700e+04</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.990000e+02</td>\n      <td>4.800000e+02</td>\n      <td>5.400000e+02</td>\n      <td>2.982028e+09</td>\n      <td>1.000000e+00</td>\n      <td>1.077488e+00</td>\n      <td>7.713682e+09</td>\n      <td>4.379531e+02</td>\n      <td>1.309732e+00</td>\n      <td>1.077488e+00</td>\n      <td>3.028784e+07</td>\n      <td>1.077836e+00</td>\n      <td>5.440500e+07</td>\n      <td>1.077675e+00</td>\n      <td>4.460704e+02</td>\n      <td>2.645400e+04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Check for Missing Data:\nDetermine if there are any missing values in the dataset. You can use the isnull() method to identify missing values and the sum() method to count them.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:51:03.707503Z","iopub.execute_input":"2024-12-14T06:51:03.707810Z","iopub.status.idle":"2024-12-14T06:51:04.064761Z","shell.execute_reply.started":"2024-12-14T06:51:03.707779Z","shell.execute_reply":"2024-12-14T06:51:04.063738Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"stock_id                         0\ndate_id                          0\nseconds_in_bucket                0\nimbalance_size                 220\nimbalance_buy_sell_flag          0\nreference_price                220\nmatched_size                   220\nfar_price                  2894342\nnear_price                 2857180\nbid_price                      220\nbid_size                         0\nask_price                      220\nask_size                         0\nwap                            220\ntarget                          88\ntime_id                          0\nrow_id                           0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Data Preprocessing\n## Handling Missing Data\nimbalance_size, reference_price, matched_size, far_price, near_price, bid_price, wap, and target has missing values. We'll use mean imputation for the numerical columns and forward fill (FFill) for the target column since it's a time series variable.","metadata":{}},{"cell_type":"code","source":"numerical_columns = ['imbalance_size', 'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'ask_price', 'wap', 'target']\n\n# Forward fill for 'target' column\ndf['target'].fillna(method='ffill', inplace=True)\n\n# Mean imputation for numerical columns\nfor column in numerical_columns:\n    mean_value = df[column].mean()\n    df[column].fillna(mean_value, inplace=True)\n\n# Check if there are any remaining missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:51:04.066043Z","iopub.execute_input":"2024-12-14T06:51:04.066370Z","iopub.status.idle":"2024-12-14T06:51:04.795444Z","shell.execute_reply.started":"2024-12-14T06:51:04.066332Z","shell.execute_reply":"2024-12-14T06:51:04.794422Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"stock_id                   0\ndate_id                    0\nseconds_in_bucket          0\nimbalance_size             0\nimbalance_buy_sell_flag    0\nreference_price            0\nmatched_size               0\nfar_price                  0\nnear_price                 0\nbid_price                  0\nbid_size                   0\nask_price                  0\nask_size                   0\nwap                        0\ntarget                     0\ntime_id                    0\nrow_id                     0\ndtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Data Encoding\nFeatures Requiring Encoding:\n\n- stock_id (Categorical): This column represents the unique identifier for each stock. We can apply one-hot encoding to convert it into binary columns for each stock.\n- imbalance_buy_sell_flag (Categorical): This column represents the direction of auction imbalance and has three categories: 1 (Buy-side imbalance), -1 (Sell-side imbalance), and 0 (No imbalance). We can apply one-hot encoding to this column to convert it into binary columns.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Make a copy of the original DataFrame\ndf_encoded = df.copy()\n\n# Apply one-hot encoding to 'stock_id' and 'imbalance_buy_sell_flag' with prefixes\ndf_encoded = pd.get_dummies(df_encoded, columns=['stock_id', 'imbalance_buy_sell_flag'], prefix=['stock', 'imbalance_flag'], drop_first=True)\n\n# Check the current column names in df_encoded\nprint(df_encoded.columns)\n\n# Drop the original columns if they exist\ncolumns_to_drop = ['stock_id', 'imbalance_buy_sell_flag']\ndf_encoded.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n\ndf_encoded.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:51:04.796711Z","iopub.execute_input":"2024-12-14T06:51:04.797027Z","iopub.status.idle":"2024-12-14T06:51:08.569721Z","shell.execute_reply.started":"2024-12-14T06:51:04.796985Z","shell.execute_reply":"2024-12-14T06:51:08.568594Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Index(['date_id', 'seconds_in_bucket', 'imbalance_size', 'reference_price',\n       'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n       'ask_price',\n       ...\n       'stock_192', 'stock_193', 'stock_194', 'stock_195', 'stock_196',\n       'stock_197', 'stock_198', 'stock_199', 'imbalance_flag_0',\n       'imbalance_flag_1'],\n      dtype='object', length=216)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   date_id  seconds_in_bucket  imbalance_size  reference_price  matched_size  \\\n0        0                  0      3180602.69         0.999812   13380276.64   \n1        0                  0       166603.91         0.999896    1642214.25   \n2        0                  0       302879.87         0.999561    1819368.03   \n3        0                  0     11917682.27         1.000171   18389745.62   \n4        0                  0       447549.96         0.999532   17860614.95   \n\n   far_price  near_price  bid_price  bid_size  ask_price  ...  stock_192  \\\n0   1.001713     0.99966   0.999812  60651.50   1.000026  ...      False   \n1   1.001713     0.99966   0.999896   3233.04   1.000660  ...      False   \n2   1.001713     0.99966   0.999403  37956.00   1.000298  ...      False   \n3   1.001713     0.99966   0.999999   2324.90   1.000214  ...      False   \n4   1.001713     0.99966   0.999394  16485.54   1.000016  ...      False   \n\n   stock_193  stock_194  stock_195 stock_196  stock_197  stock_198  stock_199  \\\n0      False      False      False     False      False      False      False   \n1      False      False      False     False      False      False      False   \n2      False      False      False     False      False      False      False   \n3      False      False      False     False      False      False      False   \n4      False      False      False     False      False      False      False   \n\n   imbalance_flag_0  imbalance_flag_1  \n0             False              True  \n1             False             False  \n2             False             False  \n3             False             False  \n4             False             False  \n\n[5 rows x 216 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>seconds_in_bucket</th>\n      <th>imbalance_size</th>\n      <th>reference_price</th>\n      <th>matched_size</th>\n      <th>far_price</th>\n      <th>near_price</th>\n      <th>bid_price</th>\n      <th>bid_size</th>\n      <th>ask_price</th>\n      <th>...</th>\n      <th>stock_192</th>\n      <th>stock_193</th>\n      <th>stock_194</th>\n      <th>stock_195</th>\n      <th>stock_196</th>\n      <th>stock_197</th>\n      <th>stock_198</th>\n      <th>stock_199</th>\n      <th>imbalance_flag_0</th>\n      <th>imbalance_flag_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3180602.69</td>\n      <td>0.999812</td>\n      <td>13380276.64</td>\n      <td>1.001713</td>\n      <td>0.99966</td>\n      <td>0.999812</td>\n      <td>60651.50</td>\n      <td>1.000026</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>166603.91</td>\n      <td>0.999896</td>\n      <td>1642214.25</td>\n      <td>1.001713</td>\n      <td>0.99966</td>\n      <td>0.999896</td>\n      <td>3233.04</td>\n      <td>1.000660</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>302879.87</td>\n      <td>0.999561</td>\n      <td>1819368.03</td>\n      <td>1.001713</td>\n      <td>0.99966</td>\n      <td>0.999403</td>\n      <td>37956.00</td>\n      <td>1.000298</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11917682.27</td>\n      <td>1.000171</td>\n      <td>18389745.62</td>\n      <td>1.001713</td>\n      <td>0.99966</td>\n      <td>0.999999</td>\n      <td>2324.90</td>\n      <td>1.000214</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>447549.96</td>\n      <td>0.999532</td>\n      <td>17860614.95</td>\n      <td>1.001713</td>\n      <td>0.99966</td>\n      <td>0.999394</td>\n      <td>16485.54</td>\n      <td>1.000016</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 216 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Feature Engineering\n1. Price Spread: Calculated as the difference between the ask price and bid price, capturing the spread between buying and selling prices.\n\n2. Volume-Weighted Average Price (VWAP): Computed separately for each stock, representing the average price at which a stock has traded throughout the day, weighted by volume.\n\n3. Rolling Mean of Matched Size: The 10-period rolling mean of the matched size, measuring trading activity over time for each stock.\n\n4. Imbalance Ratio: The ratio of the imbalance size to the matched size, indicating the degree of order imbalance in the auction.\n\n5. Cumulative Bid Size: The cumulative sum of bid sizes for each stock, showing the total demand at different time points.\n\n6. Skewness of VWAP: A measure of the asymmetry of the VWAP distribution for each stock.\n\n7. Kurtosis of VWAP: A measure of the \"tailedness\" of the VWAP distribution for each stock, assessing extreme values.\n\nThese engineered features provide valuable insights into trading dynamics and aim to enhance the predictive power of the model by capturing various aspects of price and volume behavior for each stock.","metadata":{}},{"cell_type":"code","source":"# Define a threshold for high volume\nthreshold = 10000\n\n# Calculate kurtosis of wap for each stock (custom function)\ndef custom_kurtosis(x):\n    return x.kurt()\n\nstock_columns = [col for col in df_encoded.columns if col.startswith('stock_')]\n\n# Calculate price spread\ndf_encoded['price_spread'] = df_encoded['ask_price'] - df_encoded['bid_price']\n\n# Calculate VWAP for each stock\ndf_encoded['vwap'] = df_encoded.groupby(stock_columns)['wap'].transform('mean')\n\n# Calculate rolling mean of matched_size for each stock\ndf_encoded['rolling_mean_matched_size'] = df_encoded.groupby(stock_columns)['matched_size'].transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n\n# Calculate the ratio of imbalance_size to matched_size for each stock\ndf_encoded['imbalance_ratio'] = df_encoded['imbalance_size'] / df_encoded['matched_size']\n\n# Calculate cumulative sum of bid_size for each stock\ndf_encoded['cumulative_bid_size'] = df_encoded.groupby(stock_columns)['bid_size'].cumsum()\n\n# Calculate skewness of wap for each stock\ndf_encoded['wap_skewness'] = df_encoded.groupby(stock_columns)['wap'].transform('skew')\n\n# Calculate kurtosis of wap for each stock\ndf_encoded['wap_kurtosis'] = df_encoded.groupby(stock_columns)['wap'].transform(custom_kurtosis)\n\n# Create a feature indicating high volume\ndf_encoded['is_high_volume'] = (df_encoded['bid_size'] + df_encoded['ask_size'] > threshold).astype('bool')\n\n# Display the first few rows of the DataFrame with engineered features\nprint(df_encoded.head())","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:51:08.572379Z","iopub.execute_input":"2024-12-14T06:51:08.572677Z","iopub.status.idle":"2024-12-14T06:53:01.922561Z","shell.execute_reply.started":"2024-12-14T06:51:08.572646Z","shell.execute_reply":"2024-12-14T06:53:01.921467Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   date_id  seconds_in_bucket  imbalance_size  reference_price  matched_size  \\\n0        0                  0      3180602.69         0.999812   13380276.64   \n1        0                  0       166603.91         0.999896    1642214.25   \n2        0                  0       302879.87         0.999561    1819368.03   \n3        0                  0     11917682.27         1.000171   18389745.62   \n4        0                  0       447549.96         0.999532   17860614.95   \n\n   far_price  near_price  bid_price  bid_size  ask_price  ...  \\\n0   1.001713     0.99966   0.999812  60651.50   1.000026  ...   \n1   1.001713     0.99966   0.999896   3233.04   1.000660  ...   \n2   1.001713     0.99966   0.999403  37956.00   1.000298  ...   \n3   1.001713     0.99966   0.999999   2324.90   1.000214  ...   \n4   1.001713     0.99966   0.999394  16485.54   1.000016  ...   \n\n   imbalance_flag_0  imbalance_flag_1  price_spread      vwap  \\\n0             False              True      0.000214  0.999842   \n1             False             False      0.000764  0.999929   \n2             False             False      0.000895  1.000145   \n3             False             False      0.000215  0.999977   \n4             False             False      0.000622  0.999863   \n\n  rolling_mean_matched_size  imbalance_ratio  cumulative_bid_size  \\\n0               13380276.64         0.237708             60651.50   \n1                1642214.25         0.101451              3233.04   \n2                1819368.03         0.166475             37956.00   \n3               18389745.62         0.648061              2324.90   \n4               17860614.95         0.025058             16485.54   \n\n   wap_skewness  wap_kurtosis  is_high_volume  \n0      0.130012      2.661938            True  \n1      0.307577      2.733586            True  \n2     -0.562645     11.202168            True  \n3      0.200139      3.383347            True  \n4      0.086339      1.682726            True  \n\n[5 rows x 224 columns]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Data Scaling\nIn this dataset, features with varying ranges and magnitudes, such as stock prices and trading volumes, are scaled using the Min-Max Scaling method. This process transforms the data into a common range between 0 and 1, making it more suitable for modeling and ensuring that the model's performance is not affected by differences in feature magnitudes.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\n\n# Define the columns you want to scale\ncolumns_to_scale = [\n    'imbalance_size',\n    'reference_price',\n    'matched_size',\n    'far_price',\n    'near_price',\n    'bid_price',\n    'bid_size',\n    'ask_price',\n    'ask_size',\n    'wap',\n    'price_spread',\n    'vwap',\n    'rolling_mean_matched_size',\n    'imbalance_ratio',\n    'cumulative_bid_size',\n    'wap_skewness',\n    'wap_kurtosis'\n]\n\n# Create a Min-Max Scaler instance\nscaler = StandardScaler()\n\n# df_encoded_scaled = df_encoded.copy()\n# Apply Min-Max Scaling to the specified columns\ndf_encoded[columns_to_scale] = scaler.fit_transform(df_encoded[columns_to_scale])\n\n# Display the scaled DataFrame\nprint(df_encoded.head())","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:53:01.923909Z","iopub.execute_input":"2024-12-14T06:53:01.924205Z","iopub.status.idle":"2024-12-14T06:53:04.169619Z","shell.execute_reply.started":"2024-12-14T06:53:01.924176Z","shell.execute_reply":"2024-12-14T06:53:04.168646Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   date_id  seconds_in_bucket  imbalance_size  reference_price  matched_size  \\\n0        0                  0       -0.123550        -0.072475     -0.226833   \n1        0                  0       -0.270464        -0.039305     -0.310773   \n2        0                  0       -0.263821        -0.171589     -0.309507   \n3        0                  0        0.302327         0.069285     -0.191010   \n4        0                  0       -0.256769        -0.183040     -0.194794   \n\n      far_price    near_price  bid_price  bid_size  ask_price  ...  \\\n0 -2.300533e-15 -1.082577e-13   0.034293  0.079320  -0.095019  ...   \n1 -2.300533e-15 -1.082577e-13   0.067903 -0.436007   0.157572  ...   \n2 -2.300533e-15 -1.082577e-13  -0.129353 -0.124371   0.013348  ...   \n3 -2.300533e-15 -1.082577e-13   0.109115 -0.444158  -0.020118  ...   \n4 -2.300533e-15 -1.082577e-13  -0.132954 -0.317067  -0.099003  ...   \n\n   imbalance_flag_0  imbalance_flag_1  price_spread      vwap  \\\n0             False              True     -0.555969 -1.230944   \n1             False             False      0.387206 -0.517429   \n2             False             False      0.611853  1.261013   \n3             False             False     -0.554254 -0.120199   \n4             False             False      0.143695 -1.063015   \n\n  rolling_mean_matched_size  imbalance_ratio  cumulative_bid_size  \\\n0                 -0.230236        -0.029916            -0.782706   \n1                 -0.315452        -0.241330            -0.782774   \n2                 -0.314166        -0.140439            -0.782733   \n3                 -0.193868         0.606780            -0.782775   \n4                 -0.197710        -0.359860            -0.782758   \n\n   wap_skewness  wap_kurtosis  is_high_volume  \n0      0.010179     -0.170144            True  \n1      0.243876     -0.163585            True  \n2     -0.901441      0.611605            True  \n3      0.102475     -0.104108            True  \n4     -0.047299     -0.259778            True  \n\n[5 rows x 224 columns]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"code","source":"# Drop unnecessary columns\nX = df_encoded.drop(columns=['time_id', 'row_id', 'target'])\nX[\"is_high_volume\"] = X[\"is_high_volume\"].astype(int)\n\ny = df_encoded['target']","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:53:04.171077Z","iopub.execute_input":"2024-12-14T06:53:04.171534Z","iopub.status.idle":"2024-12-14T06:53:05.614143Z","shell.execute_reply.started":"2024-12-14T06:53:04.171487Z","shell.execute_reply":"2024-12-14T06:53:05.613400Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\ndef evaluate_model(model, y, pred):\n    print(f'Mean Square Error (MSE) : ',round(mean_squared_error(y, pred), 1))\n    print(f'Mean Absolute Error (MAE) : ', round(mean_absolute_error(y, pred), 1))\n","metadata":{"execution":{"iopub.status.busy":"2024-12-14T06:53:05.615344Z","iopub.execute_input":"2024-12-14T06:53:05.615723Z","iopub.status.idle":"2024-12-14T06:53:05.782743Z","shell.execute_reply.started":"2024-12-14T06:53:05.615684Z","shell.execute_reply":"2024-12-14T06:53:05.782021Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# x_train, x_val, y_train, y_val = train_test_split(X, y,test_size=0.25,random_state=42, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:53:05.783692Z","iopub.execute_input":"2024-12-14T06:53:05.783921Z","iopub.status.idle":"2024-12-14T06:53:05.788066Z","shell.execute_reply.started":"2024-12-14T06:53:05.783896Z","shell.execute_reply":"2024-12-14T06:53:05.786997Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"# xgb = XGBRegressor(max_depth=8, n_estimators=4500, objective=\"reg:squarederror\", eval_metric=\"mae\", \n#                    tree_method=\"gpu_hist\", device=\"cuda\", reg_lambda=10, learning_rate=0.3, seed=42)\n# model = xgb.fit(x_train,y_train, eval_set=[(x_train,y_train),(x_val, y_val)], early_stopping_rounds=50, verbose=100)\n\n# pred_train = model.predict(x_train)\n# pred_val = model.predict(x_val)\n\n# print(\"Results on training set\")\n# evaluate_model(model, y_train, pred_train)\n\n# print(\"Results on validation set\")\n# evaluate_model(model, y_val, pred_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:53:05.789229Z","iopub.execute_input":"2024-12-14T06:53:05.789556Z","iopub.status.idle":"2024-12-14T06:53:05.798067Z","shell.execute_reply.started":"2024-12-14T06:53:05.789528Z","shell.execute_reply":"2024-12-14T06:53:05.797027Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# xgb = XGBRegressor(max_depth=8, n_estimators=4500, objective=\"reg:squarederror\", eval_metric=\"mae\", \n#                    tree_method=\"gpu_hist\", device=\"cuda\", reg_lambda=10, learning_rate=0.3, seed=42)\n# model = xgb.fit(x_train,y_train, eval_set=[(x_train,y_train),(x_val, y_val)], early_stopping_rounds=50, verbose=100)\n\n# pred_train = model.predict(x_train)\n# pred_val = model.predict(x_val)\n\n# print(\"Results on training set\")\n# evaluate_model(model, y_train, pred_train)\n\n# print(\"Results on validation set\")\n# evaluate_model(model, y_val, pred_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:53:05.799294Z","iopub.execute_input":"2024-12-14T06:53:05.799570Z","iopub.status.idle":"2024-12-14T06:53:05.806427Z","shell.execute_reply.started":"2024-12-14T06:53:05.799538Z","shell.execute_reply":"2024-12-14T06:53:05.805675Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Final Model","metadata":{}},{"cell_type":"code","source":"del df\ndel df_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:53:05.807384Z","iopub.execute_input":"2024-12-14T06:53:05.807614Z","iopub.status.idle":"2024-12-14T06:53:05.825941Z","shell.execute_reply.started":"2024-12-14T06:53:05.807589Z","shell.execute_reply":"2024-12-14T06:53:05.825003Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"xgb = XGBRegressor(max_depth=8, n_estimators=4500, objective=\"reg:squarederror\", \n                   tree_method=\"gpu_hist\", n_gpus = -1, device=\"cuda\", reg_lambda=10, learning_rate=0.3, seed=42)\nmodel = xgb.fit(X,y, eval_set=[(X,y)],eval_metric=[\"mae\",\"rmse\"], early_stopping_rounds=50, verbose=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T06:53:05.827193Z","iopub.execute_input":"2024-12-14T06:53:05.827533Z","iopub.status.idle":"2024-12-14T07:09:24.275243Z","shell.execute_reply.started":"2024-12-14T06:53:05.827503Z","shell.execute_reply":"2024-12-14T07:09:24.274503Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-mae:6.35969\tvalidation_0-rmse:9.38763\n[100]\tvalidation_0-mae:6.13957\tvalidation_0-rmse:8.85547\n[200]\tvalidation_0-mae:6.03734\tvalidation_0-rmse:8.62540\n[300]\tvalidation_0-mae:5.94682\tvalidation_0-rmse:8.44314\n[400]\tvalidation_0-mae:5.87090\tvalidation_0-rmse:8.30156\n[500]\tvalidation_0-mae:5.79875\tvalidation_0-rmse:8.16804\n[600]\tvalidation_0-mae:5.73285\tvalidation_0-rmse:8.05389\n[700]\tvalidation_0-mae:5.66767\tvalidation_0-rmse:7.94069\n[800]\tvalidation_0-mae:5.60179\tvalidation_0-rmse:7.83153\n[900]\tvalidation_0-mae:5.54551\tvalidation_0-rmse:7.73671\n[1000]\tvalidation_0-mae:5.49079\tvalidation_0-rmse:7.64561\n[1100]\tvalidation_0-mae:5.43956\tvalidation_0-rmse:7.56275\n[1200]\tvalidation_0-mae:5.38820\tvalidation_0-rmse:7.47997\n[1300]\tvalidation_0-mae:5.33782\tvalidation_0-rmse:7.39886\n[1400]\tvalidation_0-mae:5.28740\tvalidation_0-rmse:7.32035\n[1500]\tvalidation_0-mae:5.23898\tvalidation_0-rmse:7.24612\n[1600]\tvalidation_0-mae:5.19287\tvalidation_0-rmse:7.17548\n[1700]\tvalidation_0-mae:5.14652\tvalidation_0-rmse:7.10502\n[1800]\tvalidation_0-mae:5.10472\tvalidation_0-rmse:7.04212\n[1900]\tvalidation_0-mae:5.06178\tvalidation_0-rmse:6.97839\n[2000]\tvalidation_0-mae:5.01877\tvalidation_0-rmse:6.91331\n[2100]\tvalidation_0-mae:4.97811\tvalidation_0-rmse:6.85188\n[2200]\tvalidation_0-mae:4.93789\tvalidation_0-rmse:6.79237\n[2300]\tvalidation_0-mae:4.89903\tvalidation_0-rmse:6.73498\n[2400]\tvalidation_0-mae:4.85879\tvalidation_0-rmse:6.67487\n[2500]\tvalidation_0-mae:4.82138\tvalidation_0-rmse:6.62072\n[2600]\tvalidation_0-mae:4.78689\tvalidation_0-rmse:6.57051\n[2700]\tvalidation_0-mae:4.75317\tvalidation_0-rmse:6.52065\n[2800]\tvalidation_0-mae:4.71847\tvalidation_0-rmse:6.47151\n[2900]\tvalidation_0-mae:4.68572\tvalidation_0-rmse:6.42472\n[3000]\tvalidation_0-mae:4.65446\tvalidation_0-rmse:6.38062\n[3100]\tvalidation_0-mae:4.62226\tvalidation_0-rmse:6.33497\n[3200]\tvalidation_0-mae:4.58769\tvalidation_0-rmse:6.28443\n[3300]\tvalidation_0-mae:4.55425\tvalidation_0-rmse:6.23569\n[3400]\tvalidation_0-mae:4.52279\tvalidation_0-rmse:6.18945\n[3500]\tvalidation_0-mae:4.49329\tvalidation_0-rmse:6.14757\n[3600]\tvalidation_0-mae:4.46269\tvalidation_0-rmse:6.10430\n[3700]\tvalidation_0-mae:4.43381\tvalidation_0-rmse:6.06436\n[3800]\tvalidation_0-mae:4.40434\tvalidation_0-rmse:6.02283\n[3900]\tvalidation_0-mae:4.37463\tvalidation_0-rmse:5.98061\n[4000]\tvalidation_0-mae:4.34570\tvalidation_0-rmse:5.93954\n[4100]\tvalidation_0-mae:4.31977\tvalidation_0-rmse:5.90370\n[4200]\tvalidation_0-mae:4.29213\tvalidation_0-rmse:5.86408\n[4300]\tvalidation_0-mae:4.26476\tvalidation_0-rmse:5.82654\n[4400]\tvalidation_0-mae:4.23952\tvalidation_0-rmse:5.79103\n[4499]\tvalidation_0-mae:4.21261\tvalidation_0-rmse:5.75326\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Preprocess Test Data","metadata":{}},{"cell_type":"code","source":"def preprocess_test_data(tdf):\n    \n    # Handling missing values with mean\n    columns_for_mean_fill = [\n        'seconds_in_bucket',\n        'imbalance_size',\n        'reference_price',\n        'matched_size',\n        'far_price',\n        'near_price',\n        'bid_price',\n        'bid_size',\n        'ask_price',\n        'ask_size',\n        'wap'\n    ]\n    missing_columns = tdf[columns_for_mean_fill].columns[tdf[columns_for_mean_fill].isnull().any()].tolist()\n    for column in missing_columns:\n        tdf[column].fillna(tdf[column].mean(), inplace=True)\n    \n    # Handling missing values with 0\n    columns_for_zero_fill = [\n        'stock_id',\n        'date_id',\n        'imbalance_buy_sell_flag',\n    ]\n    missing_columns = tdf[columns_for_zero_fill].columns[tdf[columns_for_zero_fill].isnull().any()].tolist()\n    for column in missing_columns:\n        tdf[column].fillna(0, inplace=True)\n        \n    # One hot encoding\n    tdf_encoded = tdf.copy()\n    tdf_encoded = pd.get_dummies(tdf_encoded, columns=['stock_id', 'imbalance_buy_sell_flag'], prefix=['stock', 'imbalance_flag'], drop_first=True)\n    columns_to_drop = ['stock_id', 'imbalance_buy_sell_flag']\n    tdf_encoded.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n    \n    # Feature Engineering\n    threshold = 10000\n    def custom_kurtosis(x):\n        return x.kurt()\n    stock_columns = [col for col in tdf_encoded.columns if col.startswith('stock_')]\n    tdf_encoded['price_spread'] = tdf_encoded['ask_price'] - tdf_encoded['bid_price']\n    tdf_encoded['vwap'] = tdf_encoded.groupby(stock_columns)['wap'].transform('mean')\n    tdf_encoded['rolling_mean_matched_size'] = tdf_encoded.groupby(stock_columns)['matched_size'].transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n    tdf_encoded['imbalance_ratio'] = tdf_encoded['imbalance_size'] / tdf_encoded['matched_size']\n    tdf_encoded['cumulative_bid_size'] = tdf_encoded.groupby(stock_columns)['bid_size'].cumsum()\n    tdf_encoded['wap_skewness'] = tdf_encoded.groupby(stock_columns)['wap'].transform('skew')\n    tdf_encoded['wap_kurtosis'] = tdf_encoded.groupby(stock_columns)['wap'].transform(custom_kurtosis)\n    tdf_encoded['is_high_volume'] = (tdf_encoded['bid_size'] + tdf_encoded['ask_size'] > threshold).astype('bool')\n    tdf_encoded[\"is_high_volume\"] = tdf_encoded[\"is_high_volume\"].astype(int)\n    tdf_encoded.fillna(0, inplace=True)\n    \n    # Get the columns of the training data\n    training_columns = set(X.columns)\n\n    # Get the columns of the test data\n    test_columns = set(tdf_encoded.columns)\n\n    # Identify columns missing in the test data\n    missing_columns_in_test = training_columns - test_columns\n\n    # Identify columns missing in the training data\n    missing_columns_in_training = test_columns - training_columns\n\n    # Add missing columns to the test data with default values (e.g., 0 for numerical columns)\n    for col in missing_columns_in_test:\n        tdf_encoded[col] = 0  # You can adjust the default value as needed\n\n    # Remove extra columns from the test data\n    for col in missing_columns_in_training:\n        tdf_encoded.drop(columns=col, inplace=True)\n\n    # Reorder the columns in the test data to match the order in the training data\n    tdf_encoded = tdf_encoded[X.columns]\n    \n    # Define the columns you want to scale\n    columns_to_scale = [\n        'imbalance_size',\n        'reference_price',\n        'matched_size',\n        'far_price',\n        'near_price',\n        'bid_price',\n        'bid_size',\n        'ask_price',\n        'ask_size',\n        'wap',\n        'price_spread',\n        'vwap',\n        'rolling_mean_matched_size',\n        'imbalance_ratio',\n        'cumulative_bid_size',\n        'wap_skewness',\n        'wap_kurtosis'\n    ]\n\n    # Create a Scaler instance\n    scaler = StandardScaler()\n\n    # Apply Min-Max Scaling to the specified columns\n    tdf_encoded[columns_to_scale] = scaler.fit_transform(tdf_encoded[columns_to_scale])\n\n    \n    return tdf_encoded","metadata":{"execution":{"iopub.status.busy":"2024-12-14T07:10:51.802993Z","iopub.execute_input":"2024-12-14T07:10:51.803408Z","iopub.status.idle":"2024-12-14T07:10:51.818922Z","shell.execute_reply.started":"2024-12-14T07:10:51.803373Z","shell.execute_reply":"2024-12-14T07:10:51.817765Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"# Create an environment for testing\nimport optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\ncounter = 0","metadata":{"execution":{"iopub.status.busy":"2024-12-14T07:09:24.291066Z","iopub.execute_input":"2024-12-14T07:09:24.291640Z","iopub.status.idle":"2024-12-14T07:09:24.338334Z","shell.execute_reply.started":"2024-12-14T07:09:24.291595Z","shell.execute_reply":"2024-12-14T07:09:24.337449Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Iterate over test data\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    test.sort_values(by=['date_id'], inplace=True)\n    \n    # Preprocess the current batch of test data\n    tdf_encoded = preprocess_test_data(test)\n\n    # Calculate predictions for the current batch of test data\n    test_predictions = model.predict(tdf_encoded)\n\n    # Continue with the rest of the code for making predictions and submitting\n    sample_prediction['target'] = test_predictions\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2024-12-14T07:12:27.694541Z","iopub.execute_input":"2024-12-14T07:12:27.695183Z","iopub.status.idle":"2024-12-14T07:12:27.724718Z","shell.execute_reply.started":"2024-12-14T07:12:27.695150Z","shell.execute_reply":"2024-12-14T07:12:27.723742Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Iterate over test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (test, revealed_targets, sample_prediction) \u001b[38;5;129;01min\u001b[39;00m iter_test:\n\u001b[1;32m      3\u001b[0m     test\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Preprocess the current batch of test data\u001b[39;00m\n","File \u001b[0;32mcompetition.py:30\u001b[0m, in \u001b[0;36miter_test\u001b[0;34m()\u001b[0m\n","\u001b[0;31mException\u001b[0m: You can only iterate over `iter_test()` once."],"ename":"Exception","evalue":"You can only iterate over `iter_test()` once.","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}